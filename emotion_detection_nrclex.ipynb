{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Go to terminal, type in \"pip install NRCLex\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nrclex import NRCLex\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detect emotions: sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ['your', 'website', 'is', 'horrible']\n",
      "\n",
      " {'horrible': ['anger', 'disgust', 'fear', 'negative']}\n"
     ]
    }
   ],
   "source": [
    "# Assign emotion\n",
    "text = 'your website is horrible'\n",
    "  \n",
    "# Create object\n",
    "emotion = NRCLex(text)\n",
    "  \n",
    "# Using methods to classigy emotion\n",
    "print('\\n', emotion.words)\n",
    "print('\\n', emotion.affect_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \"Raw emotion scores\" output how many words triggered each emotion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The word \"horrible\" is the only emotion word, so we just have \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " {'anger': 1, 'disgust': 1, 'fear': 1, 'negative': 1}\n"
     ]
    }
   ],
   "source": [
    "print('\\n', emotion.raw_emotion_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \"Top emotions\" standardize \"raw emotion scores\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assuming each sentence can only have a total score of 1, which emotions weigh more and which emotions weigh less?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " [('fear', 0.25), ('anger', 0.25), ('negative', 0.25), ('disgust', 0.25)]\n"
     ]
    }
   ],
   "source": [
    "print('\\n', emotion.top_emotions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Why do we need to standardize? Without standardization, longer sentences can give us more false positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " {'offer': ['positive'], 'goods': ['positive'], 'expected': ['anticipation'], 'feature': ['positive'], 'prominently': ['positive'], 'including': ['positive'], 'change': ['fear']}\n",
      "\n",
      " {'positive': 5, 'anticipation': 1, 'fear': 1}\n"
     ]
    }
   ],
   "source": [
    "text = 'It is unclear what brands Amazon will offer in the stores, although the company’s private-label goods are expected to feature prominently, the people said. Amazon sells scores of products including clothes, furniture, batteries and electronic devices through many of its own labels. The plans arent yet final and could change, these people said.'\n",
    "emotion = NRCLex(text)\n",
    "print('\\n', emotion.affect_dict)\n",
    "print('\\n', emotion.raw_emotion_scores)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's look at a longer example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " {'humbled': ['positive', 'sadness'], 'challenge': ['anger', 'fear', 'negative'], 'encourage': ['joy', 'positive', 'trust'], 'growth': ['positive'], 'build': ['positive']}\n",
      "\n",
      " {'positive': 4, 'sadness': 1, 'anger': 1, 'fear': 1, 'negative': 1, 'joy': 1, 'trust': 1}\n"
     ]
    }
   ],
   "source": [
    "text = 'I am humbled and honored to be surrounded by colleagues who challenge, support and encourage me at each stage. Through them, I’ve learned work isn’t just about the tasks we set out to do, but the experiences, growth and friendships we build along the way.'\n",
    "emotion = NRCLex(text)\n",
    "print('\\n', emotion.affect_dict)\n",
    "print('\\n', emotion.raw_emotion_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detect emotions: dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>your website is very easy to use!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>your website is not good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>is this refundable?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>someone needs to be fired</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>Way too big for a 3, 4, &amp; 5 year old..... disa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                               text\n",
       "0   1                  your website is very easy to use!\n",
       "1   2                           your website is not good\n",
       "2   3                                is this refundable?\n",
       "3   4                          someone needs to be fired\n",
       "4   5  Way too big for a 3, 4, & 5 year old..... disa..."
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('test.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make sure you process the data: lemmatization etc (not shown here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>emotions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>your website is very easy to use!</td>\n",
       "      <td>{'fear': 0.0, 'anger': 0.0, 'anticip': 0.0, 't...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>your website is not good</td>\n",
       "      <td>{'fear': 0.0, 'anger': 0.0, 'anticip': 0.0, 't...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>is this refundable?</td>\n",
       "      <td>{'fear': 0.0, 'anger': 0.0, 'anticip': 0.0, 't...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>someone needs to be fired</td>\n",
       "      <td>{'fear': 0.0, 'anger': 0.0, 'anticip': 0.0, 't...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>Way too big for a 3, 4, &amp; 5 year old..... disa...</td>\n",
       "      <td>{'fear': 0.0, 'anger': 0.25, 'anticip': 0.0, '...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                               text  \\\n",
       "0   1                  your website is very easy to use!   \n",
       "1   2                           your website is not good   \n",
       "2   3                                is this refundable?   \n",
       "3   4                          someone needs to be fired   \n",
       "4   5  Way too big for a 3, 4, & 5 year old..... disa...   \n",
       "\n",
       "                                            emotions  \n",
       "0  {'fear': 0.0, 'anger': 0.0, 'anticip': 0.0, 't...  \n",
       "1  {'fear': 0.0, 'anger': 0.0, 'anticip': 0.0, 't...  \n",
       "2  {'fear': 0.0, 'anger': 0.0, 'anticip': 0.0, 't...  \n",
       "3  {'fear': 0.0, 'anger': 0.0, 'anticip': 0.0, 't...  \n",
       "4  {'fear': 0.0, 'anger': 0.25, 'anticip': 0.0, '...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['emotions'] = df['text'].apply(lambda x: NRCLex(x).affect_frequencies)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>fear</th>\n",
       "      <th>anger</th>\n",
       "      <th>anticip</th>\n",
       "      <th>trust</th>\n",
       "      <th>surprise</th>\n",
       "      <th>positive</th>\n",
       "      <th>negative</th>\n",
       "      <th>sadness</th>\n",
       "      <th>disgust</th>\n",
       "      <th>joy</th>\n",
       "      <th>anticipation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>your website is very easy to use!</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>your website is not good</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>is this refundable?</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>someone needs to be fired</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>Way too big for a 3, 4, &amp; 5 year old..... disa...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                               text  fear  anger  \\\n",
       "0   1                  your website is very easy to use!   0.0   0.00   \n",
       "1   2                           your website is not good   0.0   0.00   \n",
       "2   3                                is this refundable?   0.0   0.00   \n",
       "3   4                          someone needs to be fired   0.0   0.00   \n",
       "4   5  Way too big for a 3, 4, & 5 year old..... disa...   0.0   0.25   \n",
       "\n",
       "   anticip  trust  surprise  positive  negative  sadness  disgust  joy  \\\n",
       "0      0.0    0.0       0.0       0.0      0.00     0.00     0.00  0.0   \n",
       "1      0.0    0.2       0.2       0.2      0.00     0.00     0.00  0.2   \n",
       "2      0.0    0.0       0.0       0.0      0.00     0.00     0.00  0.0   \n",
       "3      0.0    0.0       0.0       0.0      0.00     0.00     0.00  0.0   \n",
       "4      0.0    0.0       0.0       0.0      0.25     0.25     0.25  0.0   \n",
       "\n",
       "   anticipation  \n",
       "0           NaN  \n",
       "1           0.2  \n",
       "2           NaN  \n",
       "3           NaN  \n",
       "4           NaN  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([df.drop(['emotions'], axis = 1), df['emotions'].apply(pd.Series)], axis = 1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Limitation: NRCLex can't handle negations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Limitation: NRCLex can't recognize words it doesn't know"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://github.com/metalcorebear/NRCLex\n",
    "- https://www.geeksforgeeks.org/emotion-classification-using-nrc-lexicon-in-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os import path\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last modified: 210524\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "date = datetime.today().strftime('%y%m%d')\n",
    "print ('Last modified: ' + date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3063: DtypeWarning: Columns (2,4,5,6,9,10,11,12,13,14,17,18,20,21,22,23,24,25,26,29,30,31,32,35,36,37,38,39,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,130,131,132,133,134,135,136,137,138,139,140,141,142,145,146,147,148,149,150,151,152,153,154,156,157,159,160,161,162,163,164,165,166,168,169,170,171,196,197,198,199,200,201,202,203,204,205,206,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,490,491,492,493,494,495,496,497,498,499,500,501,502,503,504,505,506,507,508,509,510,511,512,513,514,515,516,517,518,519,520,521,522,523,524,525,526,527,528,529,531,532,533,534,535,536,537,538,539,540,541,542,543,544,545,546,547,548,549,550,551,552,553,554,555,556,557,558,559,560,561,562,563,564,565,566,567,568,569,570,571,572,573,574,575,576,577,578,579,581,582,583,584,585,586,587,588,589,590,591,592,593,594,595,596,597,598,599,600,601,602,603,604,605,606,607,608,609,610,611,612,613,614,615,616,617,618,619,620,621,622,623,624,625,626,627,628,629,631) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('Investment Decision Survey (Mturk) 5.13.2019_May 28, 2020_09.38.csv', encoding = \"ISO-8859-1\")\n",
    "df = df.drop(df.index[[0,1]])\n",
    "df_duplicate = pd.read_csv('mturk_duplicate_participants.csv')\n",
    "df_bad = pd.read_csv('mturk_subjects_log.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = df.columns.drop('ResponseId')\n",
    "df[cols] = df[cols].apply(pd.to_numeric, errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n"
     ]
    }
   ],
   "source": [
    "#aarp or sec version? Dummy coding: 1 = the longer, SEC version.\n",
    "df['version'] = 1\n",
    "for i in df.index:\n",
    "    if df.at[i, 'treatment_AARP_verif'] == 4:\n",
    "        df.at[i, 'version'] = 0\n",
    "        print('here')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comprehension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reverse scoring:\n",
    "#comprehension_pre and comprehension_post\n",
    "#if the correct answer is BD, it becomes (100-x)\n",
    "#if the answer is BOTH, and x>=50, it becomes (100-(x-50))\n",
    "#if the answer is BOTH, and x<50, it becomes (100-(50-x))\n",
    "#comp_pre_9_3 and comp_pre_9_4 will each get 50 points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#columns to reverse score because the answer is BD:\n",
    "cols = [\"comp_pre_1_1\",'comp_pre_6_1','comp_post_1_1','comp_post_6_1']\n",
    "df[cols] = 100 - df[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#columns to reward an answer of \"50\" - item 2, 7, 8, and 4*\n",
    "#for item 4, the longer version and the shorter version disagree. \n",
    "#“Both” was coded as the answer for the longer version\n",
    "#“Investment advisor” the answer for the shorter version.\n",
    "\n",
    "df[\"comp_pre_4_raw\"] = df[\"comp_pre_4_1\"]\n",
    "df[\"comp_post_4_raw\"] = df[\"comp_post_4_1\"]\n",
    "\n",
    "#the special case of item 4:\n",
    "for i in df.index:\n",
    "    if df.at[i, 'comp_pre_4_1'] < 50 and df.at[i, 'version'] == 1:\n",
    "        df.at[i, 'comp_pre_4_1'] = 100 - (50 - df.at[i, 'comp_pre_4_1'])\n",
    "    elif df.at[i, 'comp_pre_4_1'] >= 50 and df.at[i, 'version'] == 1:\n",
    "        df.at[i, 'comp_pre_4_1'] =100 - (df.at[i, 'comp_pre_4_1'] - 50)\n",
    "\n",
    "for i in df.index:\n",
    "    if df.at[i, 'comp_post_4_1'] < 50 and df.at[i, 'version'] == 1:\n",
    "        df.at[i, 'comp_post_4_1'] = 100 - (50 - df.at[i, 'comp_post_4_1'])\n",
    "    elif df.at[i, 'comp_post_4_1'] >= 50 and df.at[i, 'version'] == 1:\n",
    "        df.at[i, 'comp_post_4_1'] =100 - (df.at[i, 'comp_post_4_1'] - 50)\n",
    "\n",
    "        \n",
    "#the other cases:\n",
    "\n",
    "for i in df.index:\n",
    "    if df.at[i, 'comp_pre_2_1'] < 50:\n",
    "        df.at[i, 'comp_pre_2_1'] = 100 - (50 - df.at[i, 'comp_pre_2_1'])\n",
    "    else:\n",
    "        df.at[i, 'comp_pre_2_1'] =100 - (df.at[i, 'comp_pre_2_1'] - 50)\n",
    "\n",
    "for i in df.index:\n",
    "    if df.at[i, 'comp_pre_7_1'] < 50:\n",
    "        df.at[i, 'comp_pre_7_1'] = 100 - (50 - df.at[i, 'comp_pre_7_1'])\n",
    "    else:\n",
    "        df.at[i, 'comp_pre_7_1'] =100 - (df.at[i, 'comp_pre_7_1'] - 50)\n",
    "\n",
    "for i in df.index:\n",
    "    if df.at[i, 'comp_pre_8_1'] < 50:\n",
    "        df.at[i, 'comp_pre_8_1'] = 100 - (50 - df.at[i, 'comp_pre_8_1'])\n",
    "    else:\n",
    "        df.at[i, 'comp_pre_8_1'] =100 - (df.at[i, 'comp_pre_8_1'] - 50)\n",
    "        \n",
    "for i in df.index:\n",
    "    if df.at[i, 'comp_post_2_1'] < 50:\n",
    "        df.at[i, 'comp_post_2_1'] = 100 - (50 - df.at[i, 'comp_post_2_1'])\n",
    "    else:\n",
    "        df.at[i, 'comp_post_2_1'] =100 - (df.at[i, 'comp_post_2_1'] - 50)\n",
    "\n",
    "\n",
    "for i in df.index:\n",
    "    if df.at[i, 'comp_post_7_1'] < 50:\n",
    "        df.at[i, 'comp_post_7_1'] = 100 - (50 - df.at[i, 'comp_post_7_1'])\n",
    "    else:\n",
    "        df.at[i, 'comp_post_7_1'] =100 - (df.at[i, 'comp_post_7_1'] - 50)\n",
    "\n",
    "for i in df.index:\n",
    "    if df.at[i, 'comp_post_8_1'] < 50:\n",
    "        df.at[i, 'comp_post_8_1'] = 100 - (50 - df.at[i, 'comp_post_8_1'])\n",
    "    else:\n",
    "        df.at[i, 'comp_post_8_1'] =100 - (df.at[i, 'comp_post_8_1'] - 50)\n",
    "        \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#sum up a final comprehension pre and post score\n",
    "df['comp_pre_score'] = (df['comp_pre_1_1'] + df['comp_pre_2_1'] + df['comp_pre_3_1'] + df['comp_pre_4_1'] + df['comp_pre_5_1'] + df['comp_pre_6_1'] + df['comp_pre_7_1'] + df['comp_pre_8_1'])/8\n",
    "df['comp_post_score'] = (df['comp_post_1_1'] + df['comp_post_2_1'] + df['comp_post_3_1'] + df['comp_post_4_1'] + df['comp_post_5_1'] + df['comp_post_6_1'] + df['comp_post_7_1'] + df['comp_post_8_1'])/8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comprehension change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['comp_change_1'] = df['comp_post_1_1'] - df['comp_pre_1_1']\n",
    "df['comp_change_2'] = df['comp_post_2_1'] - df['comp_pre_2_1']\n",
    "df['comp_change_3'] = df['comp_post_3_1'] - df['comp_pre_3_1']\n",
    "df['comp_change_4'] = df['comp_post_4_1'] - df['comp_pre_4_1']\n",
    "df['comp_change_5'] = df['comp_post_5_1'] - df['comp_pre_5_1']\n",
    "df['comp_change_6'] = df['comp_post_6_1'] - df['comp_pre_6_1']\n",
    "df['comp_change_7'] = df['comp_post_7_1'] - df['comp_pre_7_1']\n",
    "df['comp_change_8'] = df['comp_post_8_1'] - df['comp_pre_8_1']\n",
    "\n",
    "df['comprehension_change'] = df['comp_post_score'] - df['comp_pre_score']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#decision scores ranges from -100 to 100. -100 means definitely choose BD, 0 means weak preference, 100 means definitely choose IA.\n",
    "#decision scores are the effects coding of the decision multiplied with the strength of the decision\n",
    "df['binary_decision_pre'] = df['decision_pre_1'] - 1\n",
    "df['binary_decision_post'] = df['decision_post_1'] - 1\n",
    "\n",
    "for i in df.index:\n",
    "    if df.at[i, 'decision_pre_1'] == 1:\n",
    "        df.at[i, 'decision_pre_1'] = -1\n",
    "    else:\n",
    "        df.at[i, 'decision_pre_1'] = 1\n",
    "        \n",
    "#Decision ranges from -100 to 100\n",
    "\n",
    "df['decision_pre'] =  df['decision_pre_1'] * df['decision_pre_2_44'] \n",
    "\n",
    "for i in df.index:\n",
    "    if df.at[i, 'decision_post_1'] == 1:\n",
    "        df.at[i, 'decision_post_1'] = -1\n",
    "    else:\n",
    "        df.at[i, 'decision_post_1'] = 1\n",
    "       \n",
    "df['decision_post'] =  df['decision_post_1'] * df['decision_post_2_1']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decisions change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['decision_change'] = df['decision_post'] - df['decision_pre']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For publication purpose, here are the counts of participants excluded for analysis:\n",
      "younger: 69  ,one of them is xiaoqing, so it should be 68\n",
      "older: 2\n",
      "overall: 78  ,one of them is xiaoqing, so it should be 77\n"
     ]
    }
   ],
   "source": [
    "#exclude 1). duplicate data, 2.)bad data, 3). progress incomplete data, \n",
    "# 4). failing language/residency/age\n",
    "df['exclude_python'] = 0\n",
    "for i in df.index:\n",
    "    for k in df_bad.index:\n",
    "        if df.at[i, 'Random ID'] == df_bad.at[k, 'survey_code']:\n",
    "            df.at[i, 'exclude_python'] = 2   #this order ensures that I can count these people as participated\n",
    "    for j in df_duplicate.index:\n",
    "        if df.at[i, 'Random ID'] == df_duplicate.at[j, 'survey_code']:\n",
    "            df.at[i, 'exclude_python'] = 1\n",
    "    if df.at[i, 'Progress']!= 100:\n",
    "            df.at[i, 'exclude_python'] = 3          \n",
    "    elif df.at[i, 'lang_3'] != 1 or df.at[i, 'residence'] != 5:\n",
    "            df.at[i, 'exclude_python'] = 4      \n",
    "\n",
    "\n",
    "print ('For publication purpose, here are the counts of participants excluded for analysis:')            \n",
    "print ('younger:', len(df[(df['exclude_python'] == 2) & (df['age'] <= 35)]), ' ,one of them is xiaoqing, so it should be 68')\n",
    "print ('older:', len(df[(df['exclude_python'] == 2) & (df['age'] >= 60)]))\n",
    "print ('overall:', len(df[df['exclude_python'] == 2]),' ,one of them is xiaoqing, so it should be 77')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Decisions change#create age variables\n",
    "for i in df.index:\n",
    "    if 17 < df.at[i, 'age'] < 36:\n",
    "        df.at[i, 'age_bracket'] = 1\n",
    "    elif 35 < df.at[i, 'age'] < 60:\n",
    "        df.at[i, 'age_bracket'] = 2\n",
    "    elif 59 < df.at[i, 'age'] < 91:\n",
    "        df.at[i, 'age_bracket'] = 3\n",
    "        \n",
    "# df['age_bracket'] = 0\n",
    "# mask = (df['age'] < 60)\n",
    "# df['age_bracket'][mask] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#how much time spent on reading form crs?\n",
    "\n",
    "df['time_form_sec'] = df['treatment_tm_RAND_1_Page Submit'] + df['treatment_tm_RAND_2_Page Submit'] + df['treatment_tm_RAND_3_Page Submit'] + df['treatment_tm_RAND_4_Page Submit'] + df['treatment_tm_RAND_5_Page Submit'] + df['treatment_tm_RAND_6_Page Submit'] + df['treatment_tm_RAND_7_Page Submit'] + df['treatment_tm_RAND_8_Page Submit']\n",
    "df['time_form_aarp'] = df['treatment_tm_AARP_1_Page Submit'] + df['treatment_tm_AARP_2_Page Submit'] + df['treatment_tm_AARP_3_Page Submit'] + df['treatment_tm_AARP_4_Page Submit'] + df['treatment_tm_AARP_5_Page Submit'] + df['treatment_tm_AARP_6_Page Submit'] + df['treatment_tm_AARP_7_Page Submit']\n",
    "\n",
    "df['reading_time'] = df.fillna(0)['time_form_sec'] + df.fillna(0)['time_form_aarp']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#income?\n",
    "x = [1,2,3,4,5,6,12,13,9,10,11]\n",
    "y = [15,20,30,42.5,62.5,87.5,112.5,137.5,162.5,187.5,200]\n",
    "df['income'] = (df['income_1'].replace(x, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#race\n",
    "x = [1,2,3,4,5,6]\n",
    "y = [0,1,0,0,0,0]\n",
    "df['race'] = (df['race'].replace(x, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#subjective vs objective effectiveness\n",
    "#comprehension\n",
    "\n",
    "# df['comp_relationship'] = (df['comp_post_1_1'] + df['comp_post_2_1']) / 2\n",
    "# df['comp_obligations'] = (df['comp_post_3_1'] + df['comp_post_4_1']) / 2\n",
    "# df['comp_fees'] = (df['comp_post_5_1'] + df['comp_post_6_1']) / 2\n",
    "# df['comp_conflicts'] = (df['comp_post_7_1'] + df['comp_post_8_1']) / 2\n",
    "# df ['comp_additionalinfo'] = df['comp_post_9']\n",
    "\n",
    "# df['subj_relationship'] = df['crs_RAND_3']\n",
    "# df['subj_obligations'] = df['crs_RAND_4']\n",
    "# df['subj_fees'] = df['crs_RAND_5']\n",
    "# df['subj_conflicts'] = df['crs_RAND_6']\n",
    "# df ['subj_additionalinfo'] = df['crs_RAND_7']\n",
    "\n",
    "# df['subj_obligations'] = df['subj_obligations'].replace([4,5,6,7], [2,3,4,5])\n",
    "# df['subj_fees'] = df['subj_fees'].replace([4,5,6,7], [2,3,4,5])\n",
    "# df['subj_conflicts'] = df['subj_conflicts'].replace([4,5,6,7], [2,3,4,5])\n",
    "# df ['subj_additionalinfo'] = df['subj_additionalinfo'].replace([4,5,6,7], [2,3,4,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "#experience level\n",
    "df['experience_1'] = df['experience_1'].replace([4], [0])\n",
    "df['experience_2'] = df['experience_2'].replace([1,2,3], [1,1,0])\n",
    "df['experience_3'] = df['experience_3'].replace([4], [0])\n",
    "df['experience_4'] = df['experience_4'].replace([2], [0])\n",
    "df['experience_6'] = df['experience_6'].replace([2], [0])\n",
    "df['experience_7'] = df['experience_7'].replace([2], [0])\n",
    "df['rand_experience_sum'] = df['experience_1'] + df['experience_2'] + df['experience_3'] + df['experience_4'] + df['experience_6'] + df['experience_7']\n",
    "\n",
    "df['experience'] = 0\n",
    "mask = (df['rand_experience_sum'] > 2)\n",
    "df['experience'][mask] = 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Financial Literacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "#financial_lit_sum\n",
    "df['financial_lit_sum'] = df['financial_lit_1'] + df['financial_lit_2'] + df['financial_lit_3'] \n",
    "\n",
    "df['finlit'] = 0\n",
    "mask = (df['financial_lit_sum'] > 1)\n",
    "df['finlit'][mask] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vocab### Decisions change\n",
    "filter_col = [col for col in df if col.startswith('vocab')]\n",
    "df['vocab'] = df[filter_col].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename Duration (in seconds)\n",
    "df = df.rename({'Duration (in seconds)': 'duration'}, axis=1)\n",
    "df = df.rename({'Random ID': 'random_id'}, axis=1)\n",
    "df = df.rename({'helpful_1': 'helpful'}, axis=1)\n",
    "df = df.rename({'interesting_1': 'interesting'}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.exclude_python == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = ['ResponseId','random_id','age','gender','race','education','duration','income',\n",
    "          'comp_pre_score','comp_post_score','comprehension_change', 'helpful', 'interesting',\n",
    "          'binary_decision_pre','binary_decision_post','decision_pre', 'decision_post','decision_change', 'age_bracket',\n",
    "          'version','rand_experience_sum','experience','financial_lit_sum','finlit', 'reading_time', 'vocab',\n",
    "          'comp_pre_1_1', 'comp_pre_2_1', 'comp_pre_3_1', 'comp_pre_4_1', 'comp_pre_5_1', 'comp_pre_6_1', 'comp_pre_7_1', 'comp_pre_8_1',\n",
    "          'comp_post_1_1', 'comp_post_2_1', 'comp_post_3_1', 'comp_post_4_1', 'comp_post_5_1', 'comp_post_6_1', 'comp_post_7_1', 'comp_post_8_1', \n",
    "          'comp_change_1','comp_change_2','comp_change_3','comp_change_4','comp_change_5','comp_change_6','comp_change_7','comp_change_8',\n",
    "         'comp_pre_4_raw', 'comp_post_4_raw']\n",
    "\n",
    "df1 = df1[subset]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_csv(('mturk_wide_'+ date + '.csv'),index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
